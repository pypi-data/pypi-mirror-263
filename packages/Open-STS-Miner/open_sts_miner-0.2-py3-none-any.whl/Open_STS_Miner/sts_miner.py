from dataclasses import dataclass
import numpy
import pandas
import geopandas
import sys
import os


buffer_epsilon = 0.01 #Used to exclude points right at the buffer distance


"""
Represents a node in the pattern tree generated by Naive STS Miner
"""
class SequenceNode:
    event_type: str
    event_set: set
    parent: object
    children: list
    sequence: str
    density_ratio: float
    
    def __init__(self, event_type, event_set, parent, density_ratio):
        self.event_type = event_type
        self.event_set = event_set
        self.parent = parent
        self.children = []
        self.density_ratio = density_ratio
        
        if self.parent != None:
            parent_seq = self.parent.sequence
            
            if parent_seq == "":
                self.sequence = self.event_type
            else:
                self.sequence = f"{parent_seq} -> {self.event_type}"
        else:
            self.sequence = ""


"""
Represents a node in the pattern tree generated by Slicing STS Miner
"""
class SlicedSequenceNode:
    event_type: str
    
    tail_event_set: set
    crossing_event_set: set
    
    full_event_set: set
    
    join_sets_by_id: dict
    parent_sets_by_id: dict
    
    parent: object
    children_by_type: dict
    sequence: str
    has_different_event_classes: bool
    density_ratio: float
    
    def __init__(self, event_type: str, parent, event_classes: dict):
        self.event_type = event_type
        self.parent = parent
        self.children_by_type = {}
        
        self.tail_event_set = set()
        self.crossing_event_set = set()
        
        self.num_events = 0
        self.num_joined_events = 0
        
        self.join_sets_by_id = {}
        self.parent_sets_by_id = {}
        
        self.full_event_set = set()
        
        if self.parent != None:
            parent_seq = self.parent.sequence
            
            if parent_seq == "":
                self.sequence = self.event_type
            else:
                self.sequence = f"{parent_seq} -> {self.event_type}"
                
            self.has_different_event_classes = self.parent.has_different_event_classes
            if not self.has_different_event_classes and event_classes != None:
                if self.parent.event_type == None:
                    self.has_different_event_classes = False
                else:
                    self.has_different_event_classes = event_classes[self.event_type] != event_classes[self.parent.event_type]       
        else:
            self.sequence = ""
            #If event classes are supplied, base case must be True to avoid filtering
            #Otherwise, base case is False to allow filtering later
            self.has_different_event_classes = event_classes == None


    def calc_density_ratio(self, local_volume: float, global_densities: dict):
        if len(self.join_sets_by_id) == 0:
            self.density_ratio = -1
            
            for event_type in self.children_by_type:
                child = self.children_by_type[event_type]
                child.calc_density_ratio(local_volume, global_densities)
            return
        
        density_sum = 0
        for id in self.join_sets_by_id:
            join_set = self.join_sets_by_id[id]
            density_sum += len(join_set)
        
        density_sum /= local_volume        
        average_local_density = density_sum / len(self.join_sets_by_id)
        
        self.density_ratio = average_local_density / global_densities[self.event_type]
        
        for event_type in self.children_by_type:
            child = self.children_by_type[event_type]
            child.calc_density_ratio(local_volume, global_densities)
        
        
    #Precondition: Density ratios must already be calculated
    def prune(self, sequence_index_threshold: float, min_events: int = 0):
        new_children = {}
        for event_type in self.children_by_type:
            child = self.children_by_type[event_type]
            
            passes_test = child.density_ratio > sequence_index_threshold and len(child.full_event_set) > min_events
            if passes_test or child.density_ratio == -1:
                new_children[event_type] = child
                                
        self.children_by_type = new_children
        for event_type in self.children_by_type:
            child = self.children_by_type[event_type]
            child.prune(sequence_index_threshold, min_events)


"""
An EventDatabase represents a database of spatiotemporal events
It includes functionality to calculate event densities and density ratios
As well as functionality to mine events using Naive STS Miner and Slicing STS Miner

An EventDatabase is populated with a GeoDataFrame containing EventType, Time, and ID fields, as well as geometry coordinates
In addition to the GeoDataFrame, an EventDatabase is initialized with the spatial and temporal extent of the spce
"""
class EventDatabase:
    """
    Represents the dimensions of the space
    This is necessary to calculate volumes for global densities
    The space is assumed to be a hyperrectangle, i.e., a generalization of a rectangle in n dimensions
    """
    spatial_extent: list[float] 
    
    """
    Represents the total time length of the spatiotemporal space
    This is necessary for calculating spatiotemporal volume for global densities
    """
    time_length: float
    
    events_df: geopandas.GeoDataFrame
    event_sets_by_type: list[pandas.DataFrame]
    buffer_events_by_id: dict
    local_volume: float
    global_densities: dict
    time_events_by_id: dict
    close_events_by_id: dict
        
    def __init__(self, events_df: geopandas.GeoDataFrame, spatial_extent: list[float], time_length: float):
        if not "EventType" in events_df.columns:
            raise Exception("events_df must have EventType column!")
        
        if not "Time" in events_df.columns:
            raise Exception("events_df must have Time column!")
        
        if not "ID" in events_df.columns:
            raise Exception("events_df must have ID column! This can easily be generated using the index of a DataFrame")

        geometry_list = events_df.geom_type.tolist()
        for geometry in geometry_list:
            if geometry != "Point":
                raise Exception("All geometry in events_df must be of type Point!")
        
        self.spatial_extent = spatial_extent
        self.time_length = time_length
        self.events_df = events_df
        self.event_sets_by_type = {}
        self.buffer_events_by_id = {}
        self.global_densities = {}
        
        self.time_events_by_id = {}
        self.close_events_by_id = {}
        
        #Partition events by type and calculate global densities 
        types = self.events_df["EventType"].unique()
        for type in types:
            type_df = self.events_df[self.events_df["EventType"] == type]
            type_df = pandas.DataFrame(type_df).drop(columns=["geometry"])
            self.event_sets_by_type[type] = set(type_df["ID"].tolist())
            
            self.global_densities[type] = self.calc_global_density(type)
    
    
    """
    Finds events with a given buffer distance of point
    
    Parameters
    ----------
    events: GeoDataFrame representing a list of events with locations
    point: GeoDataFrame representing a point or points around which to buffer
    buffer_dist: Float representing radius of the desired spatial buffer
    
    Returns: GeoDataFrame of events in events which are a distance less than or equal to buffer_dist from point
    """
    def get_events_in_spatial_buffer(self, events: geopandas.GeoDataFrame, point: geopandas.GeoDataFrame, buffer_dist: float):   
        point_buffer = point.buffer(buffer_dist - buffer_epsilon)
        return events.clip(point_buffer).reset_index(drop=True)
    
    
    """
    Finds events occurring shortly after a given time
    
    Parameters
    ----------
    events: GeoDataFrame representing a list of events
    start_time: Float representing the time after which to find events
    time_threshold: Float representing how close after start_time an event must be
    
    Returns: GeoDataFrame of events in events which occur between start_time and start_time + time_threshold (exclusive)
    """
    def get_events_after_time(self, events: pandas.DataFrame, start_time: float, time_threshold: float):              
        end_time = start_time + time_threshold
        time_df = events[events["Time"].between(start_time, end_time, inclusive="neither")]
        return time_df
    
    
    """
    Count the number of events of event_type in events
    
    Parameters
    ----------
    events: DataFrame representing a list of events
    event_type: String representing an event type
    
    Returns: Int representing number of events of event_type in events
    """
    def get_num_events(self, events: pandas.DataFrame, event_type: str):
        return len(self.get_events_of_type(events, event_type))
    
    
    """
    Get events of type event_type
    
    Parameters
    ----------
    events: DataFrame representing a list of events
    event_type: String representing an event type
    
    Returns: DataFrame of events in events of type event_type
    """
    def get_events_of_type(self, events: pandas.DataFrame, event_type: str):
        output_events = events[events["EventType"] == event_type]  
        return output_events
    
    
    """
    Calculate the volume of the entire spatiotemporal space
    
    Parameters
    ----------
    None
    
    Returns: Float representing the volume of the spatiotemporal space
             This is the volume of the space multiplied by the time length
    """
    def calc_global_volume(self):
        volume = self.time_length
        for dim in self.spatial_extent:
            volume *= dim
        
        return volume
    
    
    """
    Calculate the density of an event type in the entire spatiotemporal space
    
    Parameters
    ----------
    event_type: String representing an event type
    
    Returns: Float representing density of event_type in the EventDatabase
    """
    def calc_global_density(self, event_type: str):
        num_events = self.get_num_events(self.events_df, event_type)
        volume = self.calc_global_volume()
        
        density = num_events / volume
        return density
        
    
    """
    Calculate the density of an event type around a given point
    
    Parameters
    ----------
    events: GeoDataFrame representing a list of events with locations
    event_type: String representing an event type
    point: GeoDataFrame representing a point about which to calculate density
    buffer_dist: Float representing radius of spatial buffer around point
    time: Float representing the time about which to calculate density
    time_threshold: Float representing time threshold used to calculate density
    
    Returns: Float representing density of event_type around point
    """
    def calc_density_around_point(self, events: geopandas.GeoDataFrame, event_type: str, point: geopandas.GeoDataFrame, buffer_dist: float, time: float, time_threshold: float):
        time_events = self.get_events_after_time(events, time, time_threshold)
        buffer_events = self.get_events_in_spatial_buffer(time_events, point, buffer_dist)
        events = self.get_events_of_type(buffer_events, event_type)
        
        num_events = len(events)
        volume = self.__calc_spatiotemporal_volume(buffer_dist, time_threshold)
        
        density = num_events / volume
        
        return density
    
    
    """
    Calculate the ratio of the density an event type around a given point to the density of that event type globall
    
    Parameters
    ----------
    events: GeoDataFrame representing a list of events with locations
    event_type: String representing an event type
    point: GeoDataFrame representing a point about which to calculate density ratio
    buffer_dist: Float representing radius of spatial buffer around point
    time: Float representing the time about which to calculate density ratio
    time_threshold: Float representing time threshold used to calculate density ratio
    
    Returns: Float representing ratio of density of event_type around point to global density of event_type
    """
    def calc_density_ratio_around_point(self, events: geopandas.GeoDataFrame, event_type: str, point: geopandas.GeoDataFrame, buffer_dist: float, time: float, time_threshold: float):
        local_density = self.calc_density_around_point(events, event_type, point, buffer_dist, time, time_threshold)
        global_density = self.calc_global_density(event_type)
        
        density_ratio = local_density / global_density
        return density_ratio
        
        
    """
    Mine EventDatabase for significant event sequences using the Naive STS Miner Algorithm
    
    Parameters
    ----------
    sequence_index_threshold: Float representing the minimum sequence index (i.e., density ratio) for sequence significance
    buffer_dist: Float representing the maximum spatial distance between two events to allow one event to follow another
    time_threshold: Float representing the maximum time between two events to allow one event to follow another
    
    Returns: SequenceNode representing the root of the pattern tree representing significant sequences
    """ 
    def mine_events_naive(self, sequence_index_threshold: float, buffer_dist: float, time_threshold: float):
        self.__precompute_relations_naive(buffer_dist, time_threshold)        
        root_node = SequenceNode(None, None, None, -1.0)
        
        for event_type in self.event_sets_by_type:
            events = self.event_sets_by_type[event_type]
            event_node = SequenceNode(event_type, events, root_node, -1.0)
            root_node.children.append(event_node)
            
            self.__depth_first_expand_naive(event_node, sequence_index_threshold, 
                                    buffer_dist, time_threshold)
        
        return root_node
        
     
    """
    Precompute nearby events and local volume for Naive STS Miner
    
    Parameters
    ----------
    buffer_dist: The maximum spatial distance between two events to allow one event to follow another
    time_threshold: The maximum time between two events to allow one event to follow another
    
    Returns: None
    """ 
    def __precompute_relations_naive(self, buffer_dist: float, time_threshold: float):
        buffers = self.events_df.buffer(buffer_dist - buffer_epsilon)
        for i in range(len(self.events_df["ID"])):
            event_id = self.events_df["ID"].iloc[i]
            
            buffer = buffers[i]
            buffer_events = self.events_df.clip(buffer)
            buffer_set = set(buffer_events["ID"].tolist())
            self.buffer_events_by_id[event_id] = buffer_set
            
            time_events = self.get_events_after_time(self.events_df, self.events_df["Time"].iloc[i], time_threshold)
            time_set = set(time_events["ID"].tolist())
            self.time_events_by_id[event_id] = time_set
            
            self.close_events_by_id[event_id] = buffer_set.intersection(time_set)
        
        self.local_volume = self.__calc_spatiotemporal_volume(buffer_dist, time_threshold)
       
       
    """
    Precompute nearby events and local volume for a given slice for Slicing STS Miner
    
    Parameters
    ----------
    slice_df: GeoDataFrame representing events in one temporal slice
    buffer_dist: Float representing the maximum spatial distance between two events to allow one event to follow another
    time_threshold: Float representing the maximum time between two events to allow one event to follow another
    
    Returns: Dictionary mapping event ID's to lists of close events
    """ 
    def __precompute_relations_slice(self, slice_df: geopandas.GeoDataFrame, buffer_dist: float, time_threshold: float):
        close_events_by_id = {}
        
        buffers = slice_df.buffer(buffer_dist - buffer_epsilon)
        
        for i in range(len(slice_df["ID"])):
            event_id = slice_df["ID"].iloc[i]
            
            buffer = buffers[i]
            buffer_events = slice_df.clip(buffer)
            buffer_set = set(buffer_events["ID"].tolist())
            
            time_events = self.get_events_after_time(slice_df, slice_df["Time"].iloc[i], time_threshold)
            time_set = set(time_events["ID"].tolist())
            
            close_events_by_id[event_id] = buffer_set.intersection(time_set)
            
        return close_events_by_id
        
    
    """
    Expand an event sequence in a depth-first manner for Naive STS Miner
    
    Parameters
    ----------
    node: SequenceNode representing an event sequence to be expanded
    sequence_index_threshold: Float representing the minimum sequence index (i.e., density ratio) for sequence significance
    buffer_dist: The maximum spatial distance between two events to allow one event to follow another
    time_threshold: The maximum time between two events to allow one event to follow another
    
    Returns: None
    """ 
    def __depth_first_expand_naive(self, node: SequenceNode, sequence_index_threshold: 
                            float, buffer_dist: float, time_threshold: float):
        tail_set = node.event_set
        
        for event_type in self.event_sets_by_type:
            events = self.event_sets_by_type[event_type]
            events = events.difference(tail_set)
            
            join_set, join_sets_by_id = self.__join(tail_set, events)
            
            if len(join_set) == 0:
                continue
            
            density_sum = 0
            for tail_id in join_sets_by_id:
                num_events = len(join_sets_by_id[tail_id])
                density_sum += num_events

            density_sum /= self.local_volume            
            average_local_density = density_sum / len(tail_set)
            
            global_density = self.global_densities[event_type]
            density_ratio = average_local_density / global_density
            
            if density_ratio > sequence_index_threshold:
                new_node = SequenceNode(event_type, join_set, node, density_ratio)
                node.children.append(new_node)
                self.__depth_first_expand_naive(new_node, sequence_index_threshold, buffer_dist, time_threshold)
                
  
    """
    Mine EventDatabase for significant event sequences using the Slicing STS Miner Algorithm
    This algorithm splits the dataset into overlapping temporal slices which are processed
    one at a time
    
    Parameters
    ----------
    sequence_index_threshold: Float representing the minimum sequence index (i.e., density ratio) for sequence significance
    buffer_dist: Float representing maximum spatial distance between two events to allow one event to follow another
    time_threshold: Float representing the maximum time between two events to allow one event to follow another
    slice_length: Float representing the length of each temporal slice to be processed
    max_depth: Int representing the maximum depth of recursive depth-first expansion; equivalently, the maximum length of sequences to mine; default value None
    min_events: Int representing the minimum number of times a sequence must occur to count as significant; default value 0
    event_classes: Dictionary mapping event types to classes; this is used to filter out sequences where all events are of the same type
    skip_same_type: Boolean representing whether to exclude sequences where all events are of the same type
    log_output: Boolean representing whether to log debug trace; default value False
    
    Returns: SlicedSequenceNode representing the root of the pattern tree representing significant sequences
    """ 
    def mine_events_sliced(self, sequence_index_threshold: float, buffer_dist: float, 
                           time_threshold: float, slice_length: float,
                           max_depth: int = None, min_events: int = 0, 
                           event_classes: dict = None, skip_same_type: bool = True, log_output = False):
        event_slice_dfs, slices_event_sets_by_type, overlap_sets = self.split_into_slices(time_threshold, slice_length, self.events_df)
        self.local_volume = self.__calc_spatiotemporal_volume(buffer_dist, time_threshold)
        
        root_node = SlicedSequenceNode(None, None, event_classes)
        prev_crossing_nodes = []
        
        output_file = open(os.devnull, "w")
        if log_output:
            output_file = sys.stderr
        
        for event_type in self.event_sets_by_type:
            node = SlicedSequenceNode(event_type, root_node, event_classes)
            root_node.children_by_type[event_type] = node

        for i in range(0, len(event_slice_dfs)):
            print(f"Running on slice {i + 1}/{len(event_slice_dfs)}", file=output_file)
            
            event_slice_df = event_slice_dfs[i]
            close_events_by_id = self.__precompute_relations_slice(event_slice_df, buffer_dist, time_threshold)
                        
            slice_events_by_type = slices_event_sets_by_type[i]
            overlap_set = overlap_sets[i]
            
            new_crossing_nodes = set()
            
            print(f"Expanding crossing nodes (have {len(prev_crossing_nodes)})", file=output_file)
            for crossing_node in prev_crossing_nodes:
                if len(crossing_node.crossing_event_set) == 0:
                    continue
                
                crossing_node.tail_event_set = crossing_node.crossing_event_set
                
                new_crossing_nodes = self.__depth_first_expand_sliced(crossing_node, slice_events_by_type, 
                                                                overlap_set, new_crossing_nodes, 
                                                                close_events_by_id, max_depth, 
                                                                event_classes, 0, skip_same_type)

                crossing_node.crossing_event_set = self.__calc_crossing_set(crossing_node, overlap_set)

            print(f"Finished expanding crossing nodes; now have {len(new_crossing_nodes)} new crossing nodes", file=output_file)
            
            print("Expanding base children", file=output_file)
            for event_type in root_node.children_by_type:
                if not event_type in slice_events_by_type:
                    continue
                
                child_node = root_node.children_by_type[event_type]
                
                #Start expansion from same event type in this slice
                slice_events_same_type = slice_events_by_type[event_type]
                if len(slice_events_same_type) == 0:
                    continue
                
                child_node.tail_event_set = slice_events_same_type
                
                new_crossing_nodes = self.__depth_first_expand_sliced(child_node, slice_events_by_type, 
                                                                overlap_set, new_crossing_nodes, 
                                                                close_events_by_id, max_depth, 
                                                                event_classes, 0, skip_same_type)
            print(f"Finished expanding base children; now have {len(new_crossing_nodes)} new crossing nodes", file=output_file)
            
            #Check if any previous crossing nodes need to be carried over
            for node in prev_crossing_nodes:
                if node in new_crossing_nodes:
                    continue
                
                crossing_set = self.__calc_crossing_set(node, overlap_set)
                if len(crossing_set) > 0:
                    node.crossing_set = crossing_set
                    new_crossing_nodes.add(node)
                
            prev_crossing_nodes = new_crossing_nodes
            
            print(file=output_file)
        
        root_node.calc_density_ratio(self.local_volume, self.global_densities)
        root_node.prune(sequence_index_threshold, min_events)
        
        output_file.close()
        
        return root_node
    
    
    """
    Calculate the crossing tail event set for a node
    
    Parameters
    ----------
    node: SlicedSequenceNode representing a node in the pattern tree which has just been updated
    overlap_set: Set containing overlapping events between two slices
    
    Returns: Set representing the crossing tail event set of node
    """ 
    def __calc_crossing_set(self, node: SlicedSequenceNode, overlap_set: set):
        overlap_tail_set = node.tail_event_set.intersection(overlap_set)

        crossing_set = set()
        for event in overlap_tail_set:
            parents = node.parent_sets_by_id[event]
            parents_not_overlap = parents.difference(overlap_set)

            if len(parents_not_overlap) > 0:
                crossing_set.add(event)
                
        return crossing_set
    
    
    """
    Expand an event sequence in a depth-first manner for Slicing STS Miner
    
    Parameters
    ----------
    node: SlicedSequenceNode representing an event sequence to be expanded in the current slice
    event_sets_by_type: Dictionary containing events in the current slice organized by event type
    overlap_set: Set containing events that overlap the current slice and the next slice
    crossing_nodes: Set containing current list of crossing nodes
    close_events_by_id: Dictionary representing close events to every event in this slice
    max_depth: Int representing the maximum depth to continue expansion; default value None
    event_classes: Dictionary mapping event types to classes; this is used to filter out sequences where all events are of the same type
    skip_same_type: Boolean representing whether to exclude sequences where all events are of the same type
    curr_depth: Int representing the current depth of expansion; default value 0
    
    Returns: Set containing updated crossing nodes
    """ 
    def __depth_first_expand_sliced(self, node: SlicedSequenceNode, event_sets_by_type: dict, 
                                  overlap_set: set, crossing_nodes: set, close_events_by_id: dict,
                                   max_depth: int = None, event_classes: dict = None, curr_depth: int = 0,
                                   skip_same_type: bool = True):
        
        for event_type in event_sets_by_type:
            if event_type == node.event_type and skip_same_type:
                continue
            
            new_events = event_sets_by_type[event_type]
            new_events = new_events.difference(node.tail_event_set)
            
            if not event_type in node.children_by_type:
                new_node = SlicedSequenceNode(event_type, node, event_classes)
                node.children_by_type[event_type] = new_node
            
            node_to_expand = node.children_by_type[event_type]
            join_set = self.__join_sliced(node.tail_event_set, node_to_expand, 
                                                        new_events, close_events_by_id)
            
            if len(join_set) == 0:
                continue
            
            node_to_expand.tail_event_set = join_set
            node_to_expand.full_event_set.update(join_set)
            
            crossing_set = self.__calc_crossing_set(node_to_expand, overlap_set)
            node_to_expand.crossing_event_set.update(crossing_set)

            #Expand sequence

            if len(crossing_set) > 0 and not node_to_expand in crossing_nodes:
                crossing_nodes.add(node_to_expand)
            
            can_continue = max_depth == None or curr_depth < max_depth
            
            if can_continue:
                crossing_nodes = self.__depth_first_expand_sliced(node_to_expand, event_sets_by_type, 
                                                            overlap_set, crossing_nodes, 
                                                            close_events_by_id, max_depth, 
                                                            event_classes, curr_depth + 1, skip_same_type)
                
        return crossing_nodes
                
    
    """
    Perform a spatiotemporal join to expand sequences with tail events in tail_set to include events in new_events
    This version of the join function is used for Naive STS Miner
    
    Parameters
    ----------
    tail_set: Set representing events to be joined to
    new_events: Set representing events to join to events in tail_set
    
    Returns: Set representing joined events, dictionary representing joined events for each event ID in tail_events
    """ 
    def __join(self, tail_set: set, new_events: set):
        join_events = set()
        join_sets_by_id = {}
        
        for tail_id in tail_set:
            tail_event_close_ids = self.close_events_by_id[tail_id]
            events = new_events.intersection(tail_event_close_ids)
            
            join_sets_by_id[tail_id] = events
            join_events.update(events)
            
        return join_events, join_sets_by_id
      
    
    """
    Perform a spatiotemporal join to expand sequences with tail events in tail_set to include events in new_events
    This version of the join function is used for Slicing STS Miner
    
    Parameters
    ----------
    tail_event_set: Set representing events to be joined to
    new_events: Set representing events to join to events in tail_event_set
    node_to_expand: SlicedSequenceNode representing node to be expanded
    close_events_by_id: Dictionary representing close events for each event ID in the current slice
    
    Returns: Set representing joined events
    """ 
    def __join_sliced(self, tail_event_set: set, node_to_expand: SlicedSequenceNode, 
                    new_events: set, close_events_by_id: dict):  
        join_events = set()
        
        for tail_id in tail_event_set:
            if not tail_id in close_events_by_id:
                continue
            
            events = close_events_by_id[tail_id]
            events = new_events.intersection(events)
            
            base_set = node_to_expand.join_sets_by_id.get(tail_id, set())
            node_to_expand.join_sets_by_id[tail_id] = base_set.union(events)
            
            for event_id in events:
                base_set = node_to_expand.parent_sets_by_id.get(event_id, set())
                node_to_expand.parent_sets_by_id[event_id] = base_set.union([tail_id])
            
            join_events.update(events)
            
        return join_events
        
    
    """
    Calculate the volume of the spatiotemporal space represented by buffer_dist and time_threshold
    
    Parameters
    ----------
    buffer_dist: Float representing the maximum spatial distance between two events to allow one event to follow another
    time_threshold: Float representing the maximum time between two events to allow one event to follow another
    
    Returns: Float representing volume of spatiotemporal space
    """ 
    def __calc_spatiotemporal_volume(self, buffer_dist: float, time_threshold: float):
        return self.__calc_spatial_volume(buffer_dist, len(self.spatial_extent)) * time_threshold
    
    
    """
    Calculate the volume of a "ball" of given radius in n dimensions
    
    Parameters
    ----------
    radius: Float representing radius of the ball
    n: Int representing the number of dimensions
    
    Returns: Float representing volume of the given space
    """ 
    def __calc_spatial_volume(self, radius: float, n: int):
        if n == 0:
            return 1
        
        if n == 1:
            return 2 * radius
        
        return 2 * numpy.pi / n * radius**2 * self.__calc_spatial_volume(radius, n - 2)
        
    
    """
    Split an event dataset into overlapping temporal slices
    
    Parameters
    ----------
    time_threshold: Float representing the maximum time between two events to allow one event to follow another
    slice_length: Float representing the length of each slice to be processed
    events_df: GeoDataFrame representing events to be sliced
    
    Returns: List of slice GeoDataFrames, List of dictionaries representing event sets by type, list of sets of overlap between slices
    """ 
    def split_into_slices(self, time_threshold: float, slice_length: float, events_df: geopandas.GeoDataFrame ):
        if slice_length <= time_threshold:
            raise Exception("Slice length must be less than time threshold for overlap in Slicing STS Miner to work!")
        
        event_slice_dfs = []
        slices_event_sets_by_type = []
        overlap_sets = []
        
        events_accounted_for = set()
        
        start = 0
        end = slice_length
        while end < self.time_length + time_threshold:
            slice_df = events_df[events_df["Time"].between(start, end, inclusive="left")].reset_index()
            slice_set = set(slice_df["ID"].tolist())
                        
            event_slice_dfs.append(slice_df)
            
            overlap_df = slice_df[slice_df["Time"].between(end - time_threshold, end, inclusive="left")]
            overlap_set = set(overlap_df["ID"].tolist())
            overlap_sets.append(overlap_set)
            
            event_sets_by_type = {}
            for event_type in slice_df["EventType"].unique():
                type_df = slice_df[slice_df["EventType"] == event_type]
                type_set = set(type_df["ID"].tolist())
                event_sets_by_type[event_type] = type_set
            slices_event_sets_by_type.append(event_sets_by_type)
            
            #Can end slicing once every event is accounted for
            events_accounted_for.update(slice_set)
            if len(events_accounted_for) == len(events_df):
                break
            
            start = end - time_threshold
            end = start + slice_length
                     
        return event_slice_dfs, slices_event_sets_by_type, overlap_sets
        