{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3\n",
    "\n",
    "**In this tutorial you will:**\n",
    "- Build a Chatbot connected to a code interpreter able to execute Python code [Section 1](#1-chatbotwithinterpreter-expanding-interactivity-and-functionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#imports\n",
    "from aiflows.utils.general_helpers import read_yaml_file, quick_load_api_keys\n",
    "from aiflows.backends.api_info import ApiInfo\n",
    "from aiflows.utils import serve_utils\n",
    "from aiflows.utils import colink_utils\n",
    "from aiflows.workers import run_dispatch_worker_thread\n",
    "from aiflows.base_flows import AtomicFlow\n",
    "from aiflows.messages import FlowMessage\n",
    "from aiflows import flow_verse\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from utils import compile_and_writefile, dict_to_yaml\n",
    "import json\n",
    "import copy\n",
    "#Specify path of your flow modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a local colink server\n",
    "cl = colink_utils.start_colink_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:44:17,869\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:220\u001b[0m][\u001b[32mINFO\u001b[0m] - Dispatch worker started in attached thread.\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:44:17,871\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:221\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start Worker thread\n",
    "run_dispatch_worker_thread(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:44:19,111\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:220\u001b[0m][\u001b[32mINFO\u001b[0m] - Dispatch worker started in attached thread.\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:44:19,114\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:221\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start 2nd Worker thread (in case you're making blocking calls)\n",
    "run_dispatch_worker_thread(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ChatBotWithInterpreter: Expanding Interactivity and Functionality\n",
    "\n",
    "In this section, we'll explore the implementation of a chatbot integrated with a code interpreter, offering new dimensions of interactivity and functionality. By connecting an interpreter capable of compiling and executing code to the chatbot, we unlock numerous benefits. This setup enables users to prompt the chatbot with specific tasks, allowing them to provide instructions like \"download Apple's stock prices, plot them, and save them in a PDF.\" In response, the chatbot generates tailored code to execute these tasks, and executes it. \n",
    "\n",
    "Additionally, integrating the interpreter enhances the chatbot's adaptability and versatility. By understanding the user's environment, such as their Python environment, the chatbot can execute code seamlessly within that context. This capability extends to installing necessary Python packages on-the-fly, ensuring smooth execution without requiring user intervention. Such integration enhances the chatbot's utility, making it a versatile tool for coding assistance, troubleshooting, and rapid prototyping. Furthermore, this integration ensures that all generated code is compilable, maintaining a seamless user experience and efficient task execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Leveraging ChatAtomicFlow to write a CodeGenerator Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pulling ChatAtomicFlow from FlowVerse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:44:22,807\u001b[0m][\u001b[34maiflows.flow_verse.loading:775\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[<interactive>]\u001b[0m started to sync flow module dependencies to /Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/ChatWithCompiler/flow_modules...\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:44:22,811\u001b[0m][\u001b[34maiflows.flow_verse.loading:563\u001b[0m][\u001b[32mINFO\u001b[0m] - aiflows/ChatFlowModule:coflows will be fetched from remote\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 43043.03it/s]\n",
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 70295.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:44:23,854\u001b[0m][\u001b[34maiflows.flow_verse.loading:825\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[<interactive>]\u001b[0m finished syncing\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/ChatWithCompiler/flow_modules/aiflows/ChatFlowModule']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install dependencies from FlowVerse\n",
    "dependencies = [\n",
    "    {\"url\": \"aiflows/ChatFlowModule\", \"revision\": \"main\"},\n",
    "]\n",
    "from aiflows import flow_verse\n",
    "flow_verse.sync_dependencies(dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the CodeGenerator's Default Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining prompt templates\n",
    "\n",
    "#system prompt template\n",
    "system_prompt_template = \\\n",
    "\"\"\"\n",
    "You are a world class programmer that can complete any goal with code.\n",
    "      \n",
    "Your tasks are:\n",
    "    1. Write a python code in order to achieve a goal that is given to you. This code should be able to be run by the executor.\n",
    "\n",
    "Notice that:\n",
    "    1. If you use any external libraries, you must install them withing the code (in python)\n",
    "    2. All functions you write are modular, so make sure you make imports necessary imports within the function.\n",
    "    3. You must write docstrings for every function you write.\n",
    "\n",
    "    \n",
    "Your function will then be imported and called by an executor to finish the goal, you do not need to worry about the execution part.\n",
    "The executor will give you feedback on the code you write, and you can revise your code based on the feedback.\n",
    "\n",
    "Performance Evaluation:\n",
    "1. You must write your code in python\n",
    "2. Your answer must be able to be compiled and run by the executor (i.e, do not write codeblocks)\n",
    "\n",
    "**It's important that you should only respond in JSON format as described below:**\n",
    "Response Format:\n",
    "{\n",
    "    \"language_of_code\": \"language of the code\",\n",
    "    \"code\": \"String of the code and docstrings corresponding to the goal\",\n",
    "    \"finish\": \"True if you have finished the goal, False otherwise. Take in consideration the feedback you receive to decide if you have finished the goal or not\",\n",
    "}\n",
    "Ensure your responses can be parsed by Python json.loads\n",
    "    \n",
    "**It's important that the code you generate can be written by Python write, and is human-readable. The written file must also be indented and formatted, so that it is human-readable.**\n",
    "\"\"\"\n",
    "\n",
    "#init_human_prompt_template\n",
    "#This is the prompt passed to the ChatAtomicFlow the first time its called (i.e., the user asks to accomplish a goal)\n",
    "init_human_prompt_template = \\\n",
    "\"\"\"\n",
    "\"Here is the goal you need to achieve:\n",
    "{{goal}}\"\n",
    "\"\"\"\n",
    "\n",
    "#human_prompt_template\n",
    "#This is the prompt passed to the ChatAtomicFlow after the first time its called (i.e., feedback from the code interpreter)\n",
    "human_prompt_template = \\\n",
    "\"\"\"\n",
    "Here is the goal you need to achieve:\n",
    "{{goal}}\n",
    "Here is the previous code you have written:\n",
    "{{previous_code}}\n",
    "Here is the feedback from the previous code:\n",
    "{{feedback}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config_code_generator = {\n",
    "    \"_target_\": \"CodeGeneratorFlowModule.CodeGenerator.CodeGenerator.instantiate_from_default_config\",\n",
    "    \"name\": \"CodeGenerator\",\n",
    "    \"description\": \"Writes code with given instruction\",\n",
    "    \"backend\": {\n",
    "        \"api_infos\": \"???\"\n",
    "    },\n",
    "    \"model_name\": {\n",
    "        \"openai\": \"gpt-4\"\n",
    "    },\n",
    "    \"input_interface_non_initialized\": [\"goal\"],\n",
    "\n",
    "    \"input_interface_initialized\": [\"goal\", \"previous_code\", \"feedback\"],\n",
    "\n",
    "    \"output_interface\": [\"language_of_code\", \"code\"],\n",
    "\n",
    "    \"system_message_prompt_template\": {\n",
    "        \"template\": f'{system_prompt_template}'\n",
    "    },\n",
    "  \n",
    "    \"human_message_prompt_template\": {\n",
    "        \"template\": f'{human_prompt_template}',\n",
    "        \"input_variables\": [\"goal\", \"previous_code\", \"feedback\"],\n",
    "    },\n",
    "\n",
    "    \"init_human_message_prompt_template\": {\n",
    "        \"template\": f'{init_human_prompt_template}',\n",
    "        \"input_variables\": [\"goal\"]\n",
    "    },\n",
    "    #keep as context window only the first message (system prompt template) and the last two messages (last user-assistant interaction)\n",
    "    \"previous_messages\": {\n",
    "        \"first_k\": 1,\n",
    "        \"last_k\": 2,\n",
    "    }\n",
    "}\n",
    "dict_to_yaml(default_config_code_generator, \"CodeGeneratorFlowModule/CodeGenerator.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the CodeGenerator Flow\n",
    "\n",
    "**Requirements:** We want to make sure that the CodeGenerator generates a json parsable output. Implement this in the `CodeGenerator` class by requerying the LLM if it doesn't generate a parsable output (specifying to reformat its previous output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%compile_and_writefile CodeGeneratorFlowModule/CodeGenerator.py\n",
    "\n",
    "from aiflows.base_flows import AtomicFlow\n",
    "from aiflows.messages import FlowMessage\n",
    "from flow_modules.aiflows.ChatFlowModule import ChatAtomicFlow\n",
    "import json\n",
    "\n",
    "\n",
    "class CodeGenerator(ChatAtomicFlow):\n",
    "\n",
    "    def run(self, input_message: FlowMessage):\n",
    "        input_data = input_message.data\n",
    "        json_parsable = False\n",
    "        response = None\n",
    "        \n",
    "        #ensure the response is json parsable\n",
    "        while not json_parsable:\n",
    "            \n",
    "            output = self.query_llm(input_data=input_data).strip()\n",
    "            \n",
    "            try:\n",
    "                response = json.loads(output)\n",
    "                json_parsable = True\n",
    "            \n",
    "            except (json.decoder.JSONDecodeError, json.JSONDecodeError):\n",
    "                \n",
    "                feedback = \"The previous response cannot be parsed with json.loads, it \\\n",
    "                    could be the backslashes used for escaping single quotes in the string arguments of the code are not properly \\\n",
    "                        escaped themselves within the JSON context. Next time, do not provide any comments or code blocks. \\\n",
    "                            Make sure your next response is purely json parsable.\"\n",
    "                previous_code = output\n",
    "                new_input_data = input_data.copy()\n",
    "                new_input_data = {\n",
    "                    \"goal\": input_data[\"goal\"],\n",
    "                    \"feedback\": feedback,\n",
    "                    \"previous_code\": previous_code,   \n",
    "                }\n",
    "                input_data = new_input_data\n",
    "\n",
    "        \n",
    "        reply = self.package_output_message(\n",
    "            input_message = input_message,\n",
    "            response = response\n",
    "        )\n",
    "        self.send_message(reply)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serving the CodeGenerator Flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:44:36,407\u001b[0m][\u001b[34maiflows.utils.serve_utils:116\u001b[0m][\u001b[32mINFO\u001b[0m] - Started serving CodeGeneratorFlowModule.CodeGenerator.CodeGenerator at flows:CodeGenerator.\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:44:36,410\u001b[0m][\u001b[34maiflows.utils.serve_utils:117\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:44:36,413\u001b[0m][\u001b[34maiflows.utils.serve_utils:118\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:44:36,415\u001b[0m][\u001b[34maiflows.utils.serve_utils:119\u001b[0m][\u001b[32mINFO\u001b[0m] - singleton: False\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_utils.serve_flow(\n",
    "    cl=cl,\n",
    "    flow_class_name=\"CodeGeneratorFlowModule.CodeGenerator.CodeGenerator\",\n",
    "    flow_endpoint=\"CodeGenerator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the CodeGenerator Flow:\n",
    "\n",
    "We will now test the CodeGenerator Flow by prompting the chatbot with a task and observing the generated code. We will use the following task as an example: \"Download Apple's stock prices, plot them, and save them in a PDF.\" The chatbot should generate code that accomplishes this task, and we will evaluate the generated code's quality and correctness. To showcase the limitations of using the code generator on its own, we will show that the code is not always compilable in your Python environment. To showcase we will manually uninstall, if you do have it installed, the `yfinance` package from the Python environment (which is a library the Flow will use in its answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: yfinance 0.2.37\n",
      "Uninstalling yfinance-0.2.37:\n",
      "  Successfully uninstalled yfinance-0.2.37\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall yfinance -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:46:28,640\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted 4d70e252-ca90-4483-8e1e-d5efd4821766 at flows:CodeGenerator:mounts:local:4d70e252-ca90-4483-8e1e-d5efd4821766\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:46:28,723\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:113\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:28,730\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:155\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: CodeGenerator\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:28,731\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:156\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: 4d70e252-ca90-4483-8e1e-d5efd4821766\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:28,732\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:157\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:28,734\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:158\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:42c6eadb-af55-4b04-b284-15282c340f41:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:28,739\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:159\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:28,816\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:182\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Proxy_CodeGenerator\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:48,398\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:113\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:48,407\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:155\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: InterpreterAtomicFlow\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:48,410\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:156\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: 4f934a31-c926-47f9-9205-7837c2adc4d9\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:48,411\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:157\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:48,413\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:158\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:a4432bae-8227-4f80-af70-06328261ce78:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:48,416\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:159\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:48,453\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:182\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Proxy_InterpreterAtomicFlow\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:22,397\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:113\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:22,430\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:155\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: ChatCodeInterpreter\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:22,433\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:156\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: f929a706-fcce-4a18-9cda-7f8a0dc7ef66\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:22,437\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:157\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:22,438\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:158\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:b225784b-d0ed-4239-a26b-cb72c1f7c025:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:22,439\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:159\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:22,497\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:182\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Proxy of Coder\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:39,298\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:113\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:39,308\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:155\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: ChatCodeInterpreter\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:39,310\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:156\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: f929a706-fcce-4a18-9cda-7f8a0dc7ef66\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:39,311\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:157\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:39,312\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:158\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:308af136-4d7c-4325-9466-7cfdc437b7d1:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:39,312\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:159\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:47:39,427\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:182\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Proxy of Coder\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,284\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:113\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,293\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:155\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: CodeGenerator\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,294\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:156\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: a6fafba2-7044-4a81-ba3d-c14db9ffa86f\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,296\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:157\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,298\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:158\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:91517a02-0e11-45ae-8958-6e7fbc5b2392:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,299\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:159\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,400\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:182\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Coder\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:52,058\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:113\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:52,066\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:155\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: CodeGenerator\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:52,067\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:156\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: a6fafba2-7044-4a81-ba3d-c14db9ffa86f\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:52,068\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:157\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:52,069\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:158\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:1e30877e-3b22-4516-833f-6c6210a228f3:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:52,070\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:159\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:52,178\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:182\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Coder\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:50:23,945\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:113\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:50:23,962\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:155\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: CodeGenerator\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:50:23,963\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:156\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: a6fafba2-7044-4a81-ba3d-c14db9ffa86f\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:50:23,991\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:157\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:50:23,993\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:158\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:09ba7b5e-4d0f-4319-a6ad-6d98d3b43117:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:50:23,994\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:159\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:50:24,216\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:182\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Coder\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sent:\n",
      " {'goal': \"Download Apple's stock price between 2015 and 2016, make a plot with it and save it as a pdf in './apple_stocks.pdf'\"} \n",
      "\n",
      "REPLY:\n",
      "```python\n",
      "import yfinance as yf\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "def download_and_plot_stock_price():\n",
      "    '''\n",
      "    Download Apple's stock price between 2015 and 2016, make a plot with it, and save it as a pdf.\n",
      "    '''\n",
      "    # Download Apple's stock price data\n",
      "    apple_data = yf.download('AAPL', start='2015-01-01', end='2016-12-31')\n",
      "    \n",
      "    # Plot the 'Close' price\n",
      "    plt.figure(figsize=(12, 6))\n",
      "    plt.plot(apple_data['Close'])\n",
      "    plt.title('Apple Stock Price (2015 - 2016)')\n",
      "    plt.xlabel('Date')\n",
      "    plt.ylabel('Stock Price')\n",
      "    \n",
      "    # Save the plot as a pdf\n",
      "    plt.savefig('./apple_stocks.pdf')\n",
      "    \n",
      "    return 'Plot saved as apple_stocks.pdf'\n",
      "\n",
      "# Call the function to download, plot, and save the stock price\n",
      "download_and_plot_stock_price()\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_to_yaml = os.path.join(\"CodeGeneratorFlowModule\", \"CodeGenerator.yaml\")\n",
    "default_config = read_yaml_file(path_to_yaml)\n",
    "overrides = copy.deepcopy(default_config)\n",
    "api_information = [ApiInfo(backend_used=\"openai\", api_key=os.getenv(\"OPENAI_API_KEY\"))]\n",
    "quick_load_api_keys(overrides, api_information)\n",
    "\n",
    "proxy_code_generator = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"CodeGenerator\", #TODO: SPECIFY THE ENDPOINT\n",
    "    user_id=\"local\",\n",
    "    config_overrides=overrides,\n",
    ")\n",
    "data = {\n",
    "    \"goal\": \"Download Apple's stock price between 2015 and 2016, make a plot with it and save it as a pdf in './apple_stocks.pdf'\",\n",
    "}\n",
    "input_message = proxy_code_generator.package_input_message(data)\n",
    "future = proxy_code_generator.get_reply_future(input_message)\n",
    "reply_data = future.get_data()\n",
    "print(\"Data sent:\\n\",  data, \"\\n\")\n",
    "print(f'REPLY:\\n{reply_data[\"code\"]} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you copy paste the reply from the chatbot, you will see that the code is not compilable. This is because the `yfinance` package is not installed in your Python environment. This is an example where the interpreter comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##copy paste reply by code generator and try to run code HER\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_plot_stock_price\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "##copy paste reply by code generator and try to run code HER\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def download_and_plot_stock_price():\n",
    "    '''\n",
    "    Download Apple's stock price between 2015 and 2016, make a plot with it, and save it as a pdf.\n",
    "    '''\n",
    "    # Download Apple's stock price data\n",
    "    apple_data = yf.download('AAPL', start='2015-01-01', end='2016-12-31')\n",
    "    \n",
    "    # Plot the 'Close' price\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(apple_data['Close'])\n",
    "    plt.title('Apple Stock Price (2015 - 2016)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Stock Price')\n",
    "    \n",
    "    # Save the plot as a pdf\n",
    "    plt.savefig('./apple_stocks.pdf')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function to download, plot, and save Apple's stock price\n",
    "if __name__ == '__main__':\n",
    "    download_and_plot_stock_price()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Using the Interperter Flow Module\n",
    "\n",
    "We already have an interpreter flow module implemented on the flow verse which you can checkout [here](https://huggingface.co/aiflows/InterpreterFlowModule) !\n",
    "\n",
    "Let's check out its config, serve it and test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pulling the InterpreterFlowModule from FlowVerse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:46:37,577\u001b[0m][\u001b[34maiflows.flow_verse.loading:775\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[<interactive>]\u001b[0m started to sync flow module dependencies to /Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/ChatWithCompiler/flow_modules...\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:37,581\u001b[0m][\u001b[34maiflows.flow_verse.loading:563\u001b[0m][\u001b[32mINFO\u001b[0m] - aiflows/InterpreterFlowModule:coflows will be fetched from remote\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 22 files: 100%|██████████| 22/22 [00:00<00:00, 101848.44it/s]\n",
      "Fetching 22 files: 100%|██████████| 22/22 [00:00<00:00, 8087.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:46:38,138\u001b[0m][\u001b[34maiflows.flow_verse.loading:825\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[<interactive>]\u001b[0m finished syncing\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/ChatWithCompiler/flow_modules/aiflows/ChatFlowModule',\n",
       " '/Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/ChatWithCompiler/flow_modules/aiflows/InterpreterFlowModule']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install dependencies from FlowVerse\n",
    "dependencies = [\n",
    "    {\"url\": \"aiflows/InterpreterFlowModule\", \"revision\": \"main\"},\n",
    "]\n",
    "from aiflows import flow_verse\n",
    "flow_verse.sync_dependencies(dependencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"InterpreterAtomicFlow\",\n",
      "    \"description\": \"A flow that compiles and runs codes\",\n",
      "    \"_target_\": \"flow_modules.aiflows.InterpreterFlowModule.InterpreterAtomicFlow.instantiate_from_default_config\",\n",
      "    \"max_output\": 2000,\n",
      "    \"input_interface\": [\n",
      "        \"language\",\n",
      "        \"code\"\n",
      "    ],\n",
      "    \"output_interface\": [\n",
      "        \"interpreter_output\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#print it's default config\n",
    "\n",
    "interpreter_default_config = read_yaml_file(\"flow_modules/aiflows/InterpreterFlowModule/InterpreterAtomicFlow.yaml\")\n",
    "print(json.dumps(interpreter_default_config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serving the InterpreterFlowModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:46:43,341\u001b[0m][\u001b[34maiflows.utils.serve_utils:116\u001b[0m][\u001b[32mINFO\u001b[0m] - Started serving flow_modules.aiflows.InterpreterFlowModule.InterpreterAtomicFlow at flows:InterpreterAtomicFlow.\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:43,342\u001b[0m][\u001b[34maiflows.utils.serve_utils:117\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:43,343\u001b[0m][\u001b[34maiflows.utils.serve_utils:118\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:43,345\u001b[0m][\u001b[34maiflows.utils.serve_utils:119\u001b[0m][\u001b[32mINFO\u001b[0m] - singleton: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:43,347\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:220\u001b[0m][\u001b[32mINFO\u001b[0m] - Dispatch worker started in attached thread.\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:43,363\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:221\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "serve_utils.serve_flow(\n",
    "    cl=cl,\n",
    "    flow_class_name=\"flow_modules.aiflows.InterpreterFlowModule.InterpreterAtomicFlow\",\n",
    "    flow_endpoint=\"InterpreterAtomicFlow\",\n",
    ")\n",
    "run_dispatch_worker_thread(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the InterpreterFlowModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:46:46,988\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted 4f934a31-c926-47f9-9205-7837c2adc4d9 at flows:InterpreterAtomicFlow:mounts:local:4f934a31-c926-47f9-9205-7837c2adc4d9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sent:\n",
      " {'language': 'Python', 'code': \"print('Hello, World!')\"} \n",
      "\n",
      "REPLY:\n",
      " {'interpreter_output': 'Hello, World!'} \n",
      "\n",
      "Data sent:\n",
      " {'language': 'Python', 'code': \"import yfinance as yf\\nyf.download('AAPL', start='2015-01-01', end='2016-01-01')\"} \n",
      "\n",
      "REPLY:\n",
      " {'interpreter_output': 'File \"<stdin>\", line 4, in <module>\\nModuleNotFoundError: No module named \\'yfinance\\''} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "proxy_code_interpreter = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"InterpreterAtomicFlow\", #TODO: SPECIFY THE ENDPOINT\n",
    "    user_id=\"local\",\n",
    ")\n",
    "data = [\n",
    "    #should return \"Hello, World!\"\n",
    "    {\"language\": \"Python\", \"code\": \"print('Hello, World!')\"},\n",
    "    #should return an error\n",
    "    {\"language\": \"Python\", \"code\": \"import yfinance as yf\\nyf.download('AAPL', start='2015-01-01', end='2016-01-01')\"},\n",
    "]\n",
    "\n",
    "for dp in data:\n",
    "    input_message = proxy_code_interpreter.package_input_message(dp)\n",
    "    future = proxy_code_interpreter.get_reply_future(input_message)\n",
    "    reply_data = future.get_data()\n",
    "    print(\"Data sent:\\n\",  dp, \"\\n\")\n",
    "    print(\"REPLY:\\n\", reply_data, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Combining the CodeGenerator and Interpreter Flow Modules (ChatCodeInterpreter Flow)\n",
    "\n",
    "Now that we have both the CodeGenerator and Interpreter Flow Modules, we can combine them to create a ChatCodeInterpreter Flow. This flow will leverage the CodeGenerator to generate code based on user prompts, and the Interpreter to execute the generated code. The CodeGenerator will decide when to finish generating the code and return the final output (see system prompt template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the default config of the ChatCodeInterpreter Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_human_prompt_template = \\\n",
    "\"\"\"\n",
    "Here is the goal you need to achieve:\n",
    "{{goal}}\"\n",
    "Feedback:\n",
    "Do not finish this goal yet. You will receive feedback on the code you write.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config_ChatCodeInterpreter = \\\n",
    "{\n",
    "    \"name\": \"ChatCodeInterpreter\",\n",
    "    \"description\": \"A code which generate code with the help of a interpreter\",\n",
    "\n",
    "    # TODO: Define the target\n",
    "    \"_target_\": \"ChatCodeInterpreterFlowModule.ChatCodeInterpreter.ChatCodeInterpreter.instantiate_from_default_config\",\n",
    "\n",
    "    \"input_interface\": \"goal\",\n",
    "    \"output_interface\": [\"code\",\"interpreter_output\"],\n",
    "    \n",
    "    \"subflows_config\": {\n",
    "        \"Coder\": {\n",
    "            \"_target_\": \"aiflows.base_flows.AtomicFlow.instantiate_from_default_config\",\n",
    "            \"user_id\": \"local\",\n",
    "            \"flow_endpoint\": \"CodeGenerator\",\n",
    "            \"name\": \"Proxy of Coder\",\n",
    "            \"description\": \"A proxy flow of the Coder flow.\",\n",
    "             \"backend\": {\n",
    "                \"api_infos\": \"???\",\n",
    "                \"model_name\": {\"openai\": \"gpt-4\"}\n",
    "            },\n",
    "             \"init_human_message_prompt_template\": {\n",
    "                \"template\": f'{init_human_prompt_template}',\n",
    "                \"input_variables\": [\"goal\"]\n",
    "             }\n",
    "        },\n",
    "        \"Interpreter\": {\n",
    "            \"_target_\": \"aiflows.base_flows.AtomicFlow.instantiate_from_default_config\",\n",
    "           \n",
    "            \"user_id\": \"local\",\n",
    "            \n",
    "            \"flow_endpoint\": \"InterpreterAtomicFlow\",\n",
    "            \"name\": \"Proxy of Interpreter Flow\",\n",
    "            \"description\": \"A proxy flow of the Interpreter Flow.\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "dict_to_yaml(default_config_ChatCodeInterpreter, \"ChatCodeInterpreterFlowModule/ChatCodeInterpreter.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the ChatCodeInterpreter Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%compile_and_writefile ChatCodeInterpreterFlowModule/ChatCodeInterpreter.py\n",
    "\n",
    "from aiflows.base_flows import CompositeFlow\n",
    "from aiflows.messages import FlowMessage\n",
    "from aiflows.interfaces import KeyInterface\n",
    "\n",
    "class ChatCodeInterpreter(CompositeFlow):\n",
    "        \n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_interface_generate_reply = KeyInterface(\n",
    "            keys_to_rename={\"question\": \"prompt\"},\n",
    "            keys_to_select=[\"code\", \"interpreter_output\"]\n",
    "        )\n",
    "        \n",
    "        self.first_input_interface_coder = KeyInterface(\n",
    "            keys_to_select=[\"goal\"]\n",
    "        )\n",
    "        \n",
    "        self.input_interface_coder = KeyInterface(\n",
    "            keys_to_rename={\"code\": \"previous_code\", \"interpreter_output\": \"feedback\"},\n",
    "            keys_to_select=[\"goal\", \"previous_code\", \"feedback\"]\n",
    "        )\n",
    "        \n",
    "        self.input_interface_interpreter = KeyInterface(\n",
    "            keys_to_rename={\"code\": \"code\", \"language_of_code\": \"language\"},\n",
    "            keys_to_select=[\"code\", \"language\"]\n",
    "        )\n",
    "        \n",
    "    def set_up_flow_state(self):\n",
    "        super().set_up_flow_state()\n",
    "        self.flow_state[\"previous_state\"] = None\n",
    "\n",
    "    def determine_current_state(self):\n",
    "        previous_state = self.flow_state[\"previous_state\"]\n",
    "        \n",
    "        if previous_state is None:\n",
    "            return \"Coder\"\n",
    "        \n",
    "        elif previous_state == \"Coder\":\n",
    "            if self.flow_state[\"finish\"]:\n",
    "                return \"GenerateReply\"\n",
    "            return \"Interpreter\"\n",
    "            \n",
    "        elif previous_state == \"Interpreter\":\n",
    "            return \"Coder\"\n",
    "        \n",
    "        elif \"GenerateReply\":\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Invalid state: {previous_state}\")\n",
    "                        \n",
    "    def call_coder(self):\n",
    "        \n",
    "        if self.flow_state[\"previous_state\"] is None:\n",
    "            input_interface = self.first_input_interface_coder\n",
    "        else:\n",
    "            input_interface = self.input_interface_coder\n",
    "        \n",
    "        message = self.package_input_message(\n",
    "            data = input_interface(self.flow_state),\n",
    "            dst_flow = \"Coder\"\n",
    "        )\n",
    "        self.subflows[\"Coder\"].get_reply(\n",
    "            message,\n",
    "        )\n",
    "        \n",
    "    def call_interpreter(self):\n",
    "        \n",
    "        input_interface = self.input_interface_interpreter\n",
    "        \n",
    "        message = self.package_input_message(\n",
    "            data = input_interface(self.flow_state),\n",
    "            dst_flow = \"Interpreter\"\n",
    "        )\n",
    "        \n",
    "        self.subflows[\"Interpreter\"].get_reply(\n",
    "                message,\n",
    "        )\n",
    "        \n",
    "    def generate_reply(self):\n",
    "          \n",
    "        input_interface = self.input_interface_generate_reply\n",
    "          \n",
    "        reply = self.package_output_message(\n",
    "            input_message=self.flow_state[\"initial_message\"],\n",
    "            response=input_interface(self.flow_state),\n",
    "        )\n",
    "        self.send_message(reply)\n",
    "        \n",
    "    def register_data_to_state(self, input_message):\n",
    "        \n",
    "        previous_state = self.flow_state[\"previous_state\"]\n",
    "        \n",
    "        #first call to flow\n",
    "        if previous_state is None:\n",
    "            #register initial message so we can reply to it later\n",
    "            self.flow_state[\"initial_message\"] = input_message\n",
    "            #register the question\n",
    "            self.flow_state[\"goal\"] = input_message.data[\"goal\"]\n",
    "        \n",
    "        elif previous_state == \"Coder\":\n",
    "            self.flow_state[\"code\"] = input_message.data[\"code\"]\n",
    "            self.flow_state[\"language_of_code\"] = input_message.data[\"language_of_code\"]\n",
    "            self.flow_state[\"finish\"] = input_message.data[\"finish\"]\n",
    "        \n",
    "        #case where our last call was to the safeguard\n",
    "        elif previous_state == \"Interpreter\":\n",
    "            self.flow_state[\"interpreter_output\"] = input_message.data[\"interpreter_output\"]\n",
    "\n",
    "   \n",
    "    def run(self, input_message: FlowMessage):\n",
    "        self.register_data_to_state(input_message)\n",
    "        \n",
    "        current_state = self.determine_current_state()\n",
    "        \n",
    "        if current_state == \"Coder\":\n",
    "            self.call_coder()\n",
    "            \n",
    "        elif current_state == \"Interpreter\":\n",
    "            self.call_interpreter()\n",
    "            \n",
    "        elif current_state == \"GenerateReply\":\n",
    "            self.generate_reply()\n",
    "        \n",
    "        self.flow_state[\"previous_state\"] = current_state if current_state != \"GenerateReply\" else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serve the ChatCodeInterpreter Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:46:59,295\u001b[0m][\u001b[34maiflows.utils.serve_utils:116\u001b[0m][\u001b[32mINFO\u001b[0m] - Started serving ChatCodeInterpreterFlowModule.ChatCodeInterpreter.ChatCodeInterpreter at flows:ChatCodeInterpreter.\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:59,298\u001b[0m][\u001b[34maiflows.utils.serve_utils:117\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:59,298\u001b[0m][\u001b[34maiflows.utils.serve_utils:118\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:59,299\u001b[0m][\u001b[34maiflows.utils.serve_utils:119\u001b[0m][\u001b[32mINFO\u001b[0m] - singleton: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:59,301\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:220\u001b[0m][\u001b[32mINFO\u001b[0m] - Dispatch worker started in attached thread.\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:46:59,308\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:221\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "serve_utils.serve_flow(\n",
    "    cl=cl,\n",
    "    flow_class_name=\"ChatCodeInterpreterFlowModule.ChatCodeInterpreter.ChatCodeInterpreter\",\n",
    "    flow_endpoint=\"ChatCodeInterpreter\",\n",
    ")\n",
    "\n",
    "run_dispatch_worker_thread(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping yfinance as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "#make sure we don't have yfinacne installed\n",
    "!pip uninstall yfinance -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the ChatCodeInterpreter Flow\n",
    "\n",
    "Now let's test the ChatCodeInterpreter Flow by prompting the chatbot with the same task as before: \"Download Apple's stock prices, plot them, and save them in a PDF.\" The chatbot should generate code that accomplishes this task, and the interpreter should execute the generated code (including installing the necessary packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-22 11:49:33,019\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted a6fafba2-7044-4a81-ba3d-c14db9ffa86f at flows:CodeGenerator:mounts:local:a6fafba2-7044-4a81-ba3d-c14db9ffa86f\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,068\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted 52ef45f5-daa5-44e8-81ad-0282fd616bca at flows:InterpreterAtomicFlow:mounts:local:52ef45f5-daa5-44e8-81ad-0282fd616bca\u001b[0m\n",
      "[\u001b[36m2024-03-22 11:49:33,107\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted 0d6db9e9-c926-46d9-bb9e-337a61805cfd at flows:ChatCodeInterpreter:mounts:local:0d6db9e9-c926-46d9-bb9e-337a61805cfd\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sent:\n",
      " {'id': 0, 'goal': \"Download Apple's stock price between 2015 and 2016, make a plot with it,         and save it as a pdf in Download Apple's stock price between 2015 and 2016, make a plot with             it and save it as a pdf in 'apple_stocks.pdf'\"} \n",
      "\n",
      "REPLY:\n",
      " {'code': 'import os\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\n\\ntry:\\n    import yfinance as yf\\nexcept ImportError:\\n    import pip\\n    pip.main([\\'install\\', \\'yfinance\\'])\\n    import yfinance as yf\\n\\n\\ndef download_and_plot_apple_stock(start_date, end_date, output_file):\\n    \"\"\"\\n    This function downloads Apple\\'s stock price between the given dates, plots it and saves the plot as a pdf.\\n    \\n    Parameters:\\n    start_date (str): Start date in the format \\'YYYY-MM-DD\\'.\\n    end_date (str): End date in the format \\'YYYY-MM-DD\\'.\\n    output_file (str): The name of the output file where the plot will be saved.\\n    \\n    Returns:\\n    None\\n    \"\"\"\\n    # Download Apple\\'s stock price data\\n    data = yf.download(\\'AAPL\\', start=start_date, end=end_date)\\n    \\n    # Plot the \\'Close\\' column\\n    plt.figure(figsize=(10, 5))\\n    plt.plot(data[\\'Close\\'])\\n    plt.title(\\'Apple Stock Price\\')\\n    plt.xlabel(\\'Date\\')\\n    plt.ylabel(\\'Price ($)\\')\\n    plt.grid(True)\\n    \\n    # Save the plot as a pdf\\n    plt.savefig(output_file, format=\\'pdf\\')\\n    plt.close()\\n\\n# Call the function\\nstart_date = \\'2015-01-01\\'\\nend_date = \\'2016-12-31\\'\\noutput_file = \\'apple_stocks.pdf\\'\\ndownload_and_plot_apple_stock(start_date, end_date, output_file)', 'interpreter_output': 'Output truncated. Showing the last 2000 characters.\\n\\n1 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from yfinance) (4.12.3)\\nRequirement already satisfied: html5lib>=1.1 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from yfinance) (1.1)\\nRequirement already satisfied: soupsieve>1.2 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\\nRequirement already satisfied: six>=1.9 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\\nRequirement already satisfied: webencodings in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\\nRequirement already satisfied: python-dateutil>=2.8.2 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2.9.0)\\nRequirement already satisfied: tzdata>=2022.7 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.3.2)\\nRequirement already satisfied: idna<4,>=2.5 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.6)\\nRequirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.2.1)\\nRequirement already satisfied: certifi>=2017.4.17 in /Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2023.11.17)\\nUsing cached yfinance-0.2.37-py2.py3-none-any.whl (72 kB)\\nInstalling collected packages: yfinance\\nSuccessfully installed yfinance-0.2.37\\n0\\n[*********************100%%**********************]  1 of 1 completed'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "default_config = default_config_ChatCodeInterpreter\n",
    "overrides = copy.deepcopy(default_config)\n",
    "api_information = [ApiInfo(backend_used=\"openai\", api_key=os.getenv(\"OPENAI_API_KEY\"))]\n",
    "quick_load_api_keys(overrides, api_information)\n",
    "\n",
    "proxy_code_generator = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"ChatCodeInterpreter\", #TODO: SPECIFY THE ENDPOINT\n",
    "    user_id=\"local\",\n",
    "    config_overrides=overrides,\n",
    ")\n",
    "data = [\n",
    "    {\"id\": 0, \"goal\": \"Download Apple's stock price between 2015 and 2016, make a plot with it, \\\n",
    "        and save it as a pdf in Download Apple's stock price between 2015 and 2016, make a plot with \\\n",
    "            it and save it as a pdf in 'apple_stocks.pdf'\"},\n",
    "]\n",
    "\n",
    "for dp in data:\n",
    "    input_message = proxy_code_generator.package_input_message(dp)\n",
    "    future = proxy_code_generator.get_reply_future(input_message)\n",
    "    reply_data = future.get_data()\n",
    "    print(\"Data sent:\\n\",  dp, \"\\n\")\n",
    "    print(\"REPLY:\\n\", reply_data, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how a pdf named `apple_stock_prices.pdf` is saved in the current directory. This is the pdf that was generated by the ChatAtomicFlow executerd by the interpreter Flow.\n",
    "\n",
    "You can also check out the code it generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "\n",
      "try:\n",
      "    import yfinance as yf\n",
      "except ImportError:\n",
      "    import pip\n",
      "    pip.main(['install', 'yfinance'])\n",
      "    import yfinance as yf\n",
      "\n",
      "\n",
      "def download_and_plot_apple_stock(start_date, end_date, output_file):\n",
      "    \"\"\"\n",
      "    This function downloads Apple's stock price between the given dates, plots it and saves the plot as a pdf.\n",
      "    \n",
      "    Parameters:\n",
      "    start_date (str): Start date in the format 'YYYY-MM-DD'.\n",
      "    end_date (str): End date in the format 'YYYY-MM-DD'.\n",
      "    output_file (str): The name of the output file where the plot will be saved.\n",
      "    \n",
      "    Returns:\n",
      "    None\n",
      "    \"\"\"\n",
      "    # Download Apple's stock price data\n",
      "    data = yf.download('AAPL', start=start_date, end=end_date)\n",
      "    \n",
      "    # Plot the 'Close' column\n",
      "    plt.figure(figsize=(10, 5))\n",
      "    plt.plot(data['Close'])\n",
      "    plt.title('Apple Stock Price')\n",
      "    plt.xlabel('Date')\n",
      "    plt.ylabel('Price ($)')\n",
      "    plt.grid(True)\n",
      "    \n",
      "    # Save the plot as a pdf\n",
      "    plt.savefig(output_file, format='pdf')\n",
      "    plt.close()\n",
      "\n",
      "# Call the function\n",
      "start_date = '2015-01-01'\n",
      "end_date = '2016-12-31'\n",
      "output_file = 'apple_stocks.pdf'\n",
      "download_and_plot_apple_stock(start_date, end_date, output_file)\n"
     ]
    }
   ],
   "source": [
    "print(reply_data[\"code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you copy paste the code in a new cell it should also run since it installed the necessary packages !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except ImportError:\n",
    "    import pip\n",
    "    pip.main(['install', 'yfinance'])\n",
    "    import yfinance as yf\n",
    "\n",
    "\n",
    "def download_and_plot_apple_stock(start_date, end_date, output_file):\n",
    "    \"\"\"\n",
    "    This function downloads Apple's stock price between the given dates, plots it and saves the plot as a pdf.\n",
    "    \n",
    "    Parameters:\n",
    "    start_date (str): Start date in the format 'YYYY-MM-DD'.\n",
    "    end_date (str): End date in the format 'YYYY-MM-DD'.\n",
    "    output_file (str): The name of the output file where the plot will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Download Apple's stock price data\n",
    "    data = yf.download('AAPL', start=start_date, end=end_date)\n",
    "    \n",
    "    # Plot the 'Close' column\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data['Close'])\n",
    "    plt.title('Apple Stock Price')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price ($)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot as a pdf\n",
    "    plt.savefig(output_file, format='pdf')\n",
    "    plt.close()\n",
    "\n",
    "# Call the function\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2016-12-31'\n",
    "output_file = 'apple_stocks.pdf'\n",
    "download_and_plot_apple_stock(start_date, end_date, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
