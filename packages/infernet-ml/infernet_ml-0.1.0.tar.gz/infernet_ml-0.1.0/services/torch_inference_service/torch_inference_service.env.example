# the default workflow class to load. Change this to load a custom workflow
CLASSIC_INF_WORKFLOW_CLASS=infernet_ml.workflows.inference.torch_inference_workflow.TorchInferenceWorkflow

# no pos args
CLASSIC_INF_WORKFLOW_POSITIONAL_ARGS=[]

# kw args (in this case, model is being downloaded from huggingface hub from the repo "Ritual-Net/summarizer_models" and the file "model.torch")
CLASSIC_INF_WORKFLOW_KW_ARGS='{"model_source":"HUGGINGFACE_HUB", "model_args": {"repo_id": "Ritual-Net/summarizer_models", "filename": "model.torch"}}'

# huggingface token
HUGGING_FACE_HUB_TOKEN=YOUR_TOKEN_HERE

# whether the model is a torch JIT file (as opposed to pickle) Currently only pickle supported.
USE_JIT=false
